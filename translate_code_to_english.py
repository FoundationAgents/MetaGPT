#!/usr/bin/env python3
"""
Script to translate Chinese comments and strings to English in code files.
This ensures the code follows open source conventions.
"""

import os
import re
from pathlib import Path

# Chinese to English translation mapping
TRANSLATIONS = {
    # Comments and docstrings
    "ä¿®å¤ Ollama API å“åº”è§£æï¼Œæ”¯æŒå¤šè¡Œ JSON æµå¼å“åº”": "Fix Ollama API response parsing, support multi-line JSON streaming responses",
    "è·å–åŸå§‹æ•°æ®": "Get raw data",
    "ç§»é™¤å¯èƒ½çš„ BOM æ ‡è®°": "Remove possible BOM markers",
    "å¤„ç†å¤šè¡Œ JSONï¼ˆæµå¼å“åº”ï¼‰": "Process multi-line JSON (streaming responses)",
    "è·³è¿‡ SSE æ ¼å¼çš„ \"data: \" å‰ç¼€": "Skip SSE format \"data: \" prefix",
    "è·³è¿‡ç»“æŸæ ‡è®°": "Skip end markers",
    "å°è¯•è§£ææ¯ä¸€è¡Œ JSON": "Try to parse each line of JSON",
    "å¦‚æœå•è¡Œè§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯éƒ¨åˆ†æ•°æ®ï¼Œè·³è¿‡": "If single line parsing fails, it might be partial data, skip",
    "å¦‚æœæœ‰å¤šä¸ª JSON å¯¹è±¡ï¼Œè¿”å›æœ€åä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„å“åº”ï¼‰": "If there are multiple JSON objects, return the last one (usually the complete response)",
    "å¦‚æœæ²¡æœ‰æˆåŠŸè§£æçš„ JSONï¼Œå°è¯•è§£ææ•´ä¸ªæ•°æ®": "If no JSON was successfully parsed, try to parse the entire data",
    
    # Error messages and logs
    "å¦‚æœæ‰€æœ‰è§£æéƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯": "If all parsing fails, return error message",
    "Ollama API å“åº”è§£æå¤±è´¥": "Ollama API response parsing failed",
    "åŸå§‹æ•°æ®": "Raw data",
    "JSON è§£æå¤±è´¥": "JSON parsing failed",
    "Ollama API å“åº”è§£æå®Œå…¨å¤±è´¥": "Ollama API response parsing completely failed",
    "å“åº”è§£æå¤±è´¥": "Response parsing failed",
    "ä¼˜å…ˆå¤„ç†å¼‚å¸¸å“åº”": "Prioritize handling exception responses",
    "è¿”å›é”™è¯¯ä¿¡æ¯å’Œéƒ¨åˆ†åŸå§‹æ•°æ®": "Return error message and partial raw data",
    "æ­£å¸¸å“åº”": "Normal response",
    "å…œåº•è¿”å›å…¨éƒ¨å†…å®¹": "Fallback to return all content",
    
    # Language detector
    "è¯­è¨€æ£€æµ‹æ¨¡å—ï¼Œä½¿ç”¨å­—ç¬¦çº§åˆ«çš„æ£€æµ‹æ–¹æ³•": "Language detection module using character-level detection methods",
    "è¯­è¨€æ£€æµ‹ç»“æœ": "Language detection result",
    "è¯­è¨€æ£€æµ‹å™¨ï¼Œä½¿ç”¨å­—ç¬¦çº§åˆ«çš„æ£€æµ‹æ–¹æ³•": "Language detector using character-level detection methods",
    "è¯­è¨€æ˜ å°„è¡¨": "Language mapping table",
    "å­—ç¬¦çº§åˆ«çš„è¯­è¨€æ£€æµ‹è§„åˆ™": "Character-level language detection rules",
    "æ±‰å­—": "Chinese characters",
    "å¹³å‡åå’Œç‰‡å‡å": "Hiragana and Katakana",
    "éŸ©æ–‡": "Korean characters",
    "è‹±æ–‡å­—æ¯": "English letters",
    "ä¿„æ–‡": "Russian characters",
    "é˜¿æ‹‰ä¼¯æ–‡": "Arabic characters",
    
    # Function docstrings and comments
    "æ£€æµ‹æ–‡æœ¬è¯­è¨€": "Detect text language",
    "è¦æ£€æµ‹çš„æ–‡æœ¬": "Text to detect",
    "æ˜¯å¦ä½¿ç”¨LLMæ£€æµ‹": "Whether to use LLM detection",
    "æ£€æµ‹ç»“æœ": "Detection result",
    "ç¬¬ä¸€å±‚ï¼šå­—ç¬¦çº§åˆ«çš„æ£€æµ‹": "Layer 1: Character-level detection",
    "å¦‚æœå­—ç¬¦æ£€æµ‹ç½®ä¿¡åº¦å¾ˆé«˜ï¼Œç›´æ¥è¿”å›": "If character detection confidence is high, return directly",
    "ç¬¬äºŒå±‚ï¼šLLMè¯­ä¹‰æ£€æµ‹ï¼ˆå¦‚æœå¯ç”¨ä¸”å­—ç¬¦æ£€æµ‹ç½®ä¿¡åº¦è¾ƒä½ï¼‰": "Layer 2: LLM semantic detection (if enabled and character detection confidence is low)",
    "LLMè¯­è¨€æ£€æµ‹å¤±è´¥": "LLM language detection failed",
    "è¿”å›å­—ç¬¦æ£€æµ‹ç»“æœ": "Return character detection result",
    "å­—ç¬¦çº§åˆ«çš„è¯­è¨€æ£€æµ‹": "Character-level language detection",
    "è®¡ç®—æ¯ç§è¯­è¨€çš„å­—ç¬¦åŒ¹é…åº¦": "Calculate character matching degree for each language",
    "è¿”å›å­—ç¬¦Detection result": "Return character detection result",
    "è®¡ç®—åŒ¹é…çš„å­—ç¬¦æ•°é‡": "Calculate the number of matching characters",
    "æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„è¯­è¨€": "Find the language with the highest score",
    "è®¡ç®—ç½®ä¿¡åº¦": "Calculate confidence",
    "å°†å¾—åˆ†è½¬æ¢ä¸ºç½®ä¿¡åº¦": "Convert score to confidence",
    "å¦‚æœæœ€é«˜å¾—åˆ†å¾ˆä½ï¼Œå¯èƒ½æ˜¯æ··åˆè¯­è¨€æˆ–æœªçŸ¥è¯­è¨€": "If the highest score is low, it might be mixed language or unknown language",
    "ä½¿ç”¨LLMè¿›è¡Œè¯­ä¹‰è¯­è¨€æ£€æµ‹": "Use LLM for semantic language detection",
    "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦è¡¨è¾¾è¯­è¨€ï¼Œè€ƒè™‘è¯­ä¹‰å’Œè¡¨è¾¾ä¹ æƒ¯ã€‚": "Please analyze the main expression language of the following text, considering semantics and expression habits.",
    "æ–‡æœ¬ï¼š": "Text:",
    "è¯·åªè¿”å›è¯­è¨€åç§°ï¼Œå¦‚ï¼šChineseã€Englishã€í•œêµ­ì–´ã€Japaneseã€EspaÃ±olã€FranÃ§aisç­‰ã€‚": "Please only return the language name, such as: Chinese, English, Korean, Japanese, Spanish, French, etc.",
    "ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼Œåªè¿”å›è¯­è¨€åç§°ã€‚": "Do not include any other content, only return the language name.",
    "å¤„ç†ä¸åŒç±»å‹çš„å“åº”": "Handle different types of responses",
    "æ ‡å‡†åŒ–è¯­è¨€åç§°": "Standardize language names",
    "LLMè¯­è¨€æ£€æµ‹å¼‚å¸¸": "LLM language detection exception",
    "æ¸…ç†å’Œæ ‡å‡†åŒ–": "Clean and standardize",
    "æŸ¥æ‰¾æ˜ å°„": "Find mapping",
    "å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œè¿”å›åŸå€¼æˆ–é»˜è®¤å€¼": "If no mapping is found, return the original value or default value",
    "è·å–è¯­è¨€åç§°": "Get language name",
    "å…¨å±€è¯­è¨€æ£€æµ‹å™¨å®ä¾‹": "Global language detector instance",
    "è·å–å…¨å±€è¯­è¨€æ£€æµ‹å™¨å®ä¾‹": "Get global language detector instance",
    
    # Common patterns
    "ä¸­æ–‡": "Chinese",
    "æ—¥æœ¬èª": "Japanese",
    "éŸ©æ–‡": "Korean",
    "è‹±æ–‡": "English",
    "ä¿„æ–‡": "Russian",
    "é˜¿æ‹‰ä¼¯æ–‡": "Arabic",
}

def translate_file(file_path):
    """Translate Chinese text to English in a single file."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # Replace Chinese text with English
        for chinese, english in TRANSLATIONS.items():
            content = content.replace(chinese, english)
        
        # If content changed, write back to file
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… Translated: {file_path}")
            return True
        else:
            print(f"â­ï¸  No changes: {file_path}")
            return False
            
    except Exception as e:
        print(f"âŒ Error processing {file_path}: {e}")
        return False

def main():
    """Main function to process all Python files."""
    # Directories to process
    directories = [
        "metagpt/provider",
        "metagpt/utils", 
        "metagpt/tools/libs",
        "tests/metagpt/provider/ollama_integration",
        "tests/multilingual"
    ]
    
    total_files = 0
    translated_files = 0
    
    for directory in directories:
        if os.path.exists(directory):
            for file_path in Path(directory).rglob("*.py"):
                total_files += 1
                if translate_file(file_path):
                    translated_files += 1
    
    print(f"\nğŸ“Š Summary:")
    print(f"Total files processed: {total_files}")
    print(f"Files translated: {translated_files}")
    print(f"Files unchanged: {total_files - translated_files}")

if __name__ == "__main__":
    main() 