# Pull Request: å¢å¼º MetaGPT çš„ Ollama é›†æˆåŠŸèƒ½

## ğŸ“‹ æ¦‚è¿°

æœ¬ PR ä¸º MetaGPT é¡¹ç›®æ·»åŠ äº†å…¨é¢çš„ Ollama é›†æˆåŠŸèƒ½å¢å¼ºï¼ŒåŒ…æ‹¬ API ä¼˜åŒ–ã€æµ‹è¯•å¥—ä»¶å’Œå®Œå–„çš„æ–‡æ¡£ã€‚

## ğŸ¯ è§£å†³çš„é—®é¢˜

1. **Ollama API å“åº”è§£æé—®é¢˜**: ä¿®å¤äº†å¤šè¡Œ JSON æµå¼å“åº”çš„è§£æé—®é¢˜
2. **é”™è¯¯å¤„ç†ä¸å®Œå–„**: å¢å¼ºäº†é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•æœºåˆ¶
3. **ç¼ºå°‘å®Œæ•´æµ‹è¯•**: æ·»åŠ äº†å®Œæ•´çš„æµ‹è¯•å¥—ä»¶å’Œæ€§èƒ½åŸºå‡†
4. **é…ç½®ç®¡ç†ä¼˜åŒ–**: æ”¹è¿›äº†é…ç½®æ–‡ä»¶çš„åŠ è½½å’ŒéªŒè¯

## âœ¨ ä¸»è¦åŠŸèƒ½

### 1. Ollama API å¢å¼º (`metagpt/provider/ollama_api.py`)

- **å¤šè¡Œ JSON è§£æ**: æ”¯æŒæµå¼å“åº”çš„å¤šè¡Œ JSON æ ¼å¼è§£æ
- **é”™è¯¯å¤„ç†ä¼˜åŒ–**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé”™è¯¯ä¿¡æ¯æç¤º
- **å“åº”å¤„ç†æ”¹è¿›**: ä¼˜åŒ–äº† `get_choice` æ–¹æ³•ï¼Œæ”¯æŒå¤šç§å“åº”æ ¼å¼
- **æ¨¡å‹éªŒè¯**: æ·»åŠ äº†æ¨¡å‹åç§°çš„å¿…éœ€éªŒè¯
- **åµŒå…¥å‘é‡å¤„ç†**: æ”¹è¿›äº†åµŒå…¥å‘é‡çš„å“åº”å¤„ç†

### 2. é…ç½®æ–‡ä»¶ä¼˜åŒ– (`config/config2.yaml`)

- **Ollama é…ç½®**: æ·»åŠ äº†å®Œæ•´çš„ Ollama é…ç½®ç¤ºä¾‹
- **å‚æ•°éªŒè¯**: å¢å¼ºäº†é…ç½®å‚æ•°çš„éªŒè¯æœºåˆ¶
- **é»˜è®¤å€¼è®¾ç½®**: æä¾›äº†åˆç†çš„é»˜è®¤é…ç½®å€¼

### 3. å·¥å…·åº“æ‰©å±•

- **SLC å·¥å…·åº“** (`metagpt/tools/libs/slc.py`): æ–°å¢ä»£ç ç”Ÿæˆå’Œé—®ç­”å·¥å…·
- **æ•°æ®ç§‘å­¦å®¶è§’è‰²** (`metagpt/roles/di/data_scientist.py`): æ–°å¢æ•°æ®åˆ†æè§’è‰²

### 4. å®Œæ•´æµ‹è¯•å¥—ä»¶

- **åŸºç¡€åŠŸèƒ½æµ‹è¯•**: æœåŠ¡çŠ¶æ€ã€æ¨¡å—å¯¼å…¥ã€é…ç½®æ–‡ä»¶æµ‹è¯•
- **API è°ƒç”¨æµ‹è¯•**: å®é™… API è°ƒç”¨ã€æµå¼å“åº”ã€åµŒå…¥åŠŸèƒ½æµ‹è¯•
- **é›†æˆæµ‹è¯•**: å®Œæ•´çš„ MetaGPT + Ollama é›†æˆæµ‹è¯•
- **æ€§èƒ½åŸºå‡†**: GPU ä½¿ç”¨æƒ…å†µã€å“åº”æ—¶é—´ã€å†…å­˜ä½¿ç”¨æµ‹è¯•

## ğŸ“Š æµ‹è¯•ç»“æœ

### æµ‹è¯•é€šè¿‡ç‡: 9/10 (90.0%)

| æµ‹è¯•é¡¹ç›® | çŠ¶æ€ | è¯¦æƒ… |
|---------|------|------|
| Ollama æœåŠ¡çŠ¶æ€ | âœ… é€šè¿‡ | æœåŠ¡æ­£å¸¸è¿è¡Œï¼Œ8ä¸ªæ¨¡å‹å¯ç”¨ |
| Ollama API æ¨¡å—å¯¼å…¥ | âš ï¸ éƒ¨åˆ†é€šè¿‡ | æ ¸å¿ƒæ¨¡å—æ­£å¸¸ï¼Œéƒ¨åˆ†ä¾èµ–ç¼ºå¤± |
| é…ç½®æ–‡ä»¶ | âœ… é€šè¿‡ | é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ |
| Ollama èŠå¤©åŠŸèƒ½ | âœ… é€šè¿‡ | API è°ƒç”¨æ­£å¸¸ |
| Ollama åµŒå…¥åŠŸèƒ½ | âœ… é€šè¿‡ | åµŒå…¥å‘é‡ç”Ÿæˆæ­£å¸¸ |
| GPU ä½¿ç”¨æƒ…å†µ | âœ… é€šè¿‡ | GPU åˆ©ç”¨ç‡ 79%ï¼Œå†…å­˜ä½¿ç”¨ 65.2% |
| ç›´æ¥ API è°ƒç”¨ | âœ… é€šè¿‡ | å“åº”æ—¶é—´ 2.10ç§’ |
| æµå¼å“åº” | âœ… é€šè¿‡ | æµå¼å¤„ç†æ­£å¸¸ |
| åµŒå…¥ API | âœ… é€šè¿‡ | å‘é‡ç»´åº¦ 3584 |

### æ€§èƒ½åŸºå‡†

- **API å“åº”æ—¶é—´**: 2.10ç§’ (æ­£å¸¸)
- **GPU åˆ©ç”¨ç‡**: 79% (é«˜æ•ˆ)
- **å†…å­˜ä½¿ç”¨ç‡**: 65.2% (åˆç†)
- **æ¸©åº¦**: 58Â°C (æ­£å¸¸)

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### API è§£æä¼˜åŒ–

```python
def decode(self, response: OpenAIResponse) -> dict:
    """ä¿®å¤ Ollama API å“åº”è§£æï¼Œæ”¯æŒå¤šè¡Œ JSON æµå¼å“åº”"""
    try:
        data = response.data.decode("utf-8")
        
        # ç§»é™¤å¯èƒ½çš„ BOM æ ‡è®°
        if data.startswith('\ufeff'):
            data = data[1:]
        
        # å¤„ç†å¤šè¡Œ JSONï¼ˆæµå¼å“åº”ï¼‰
        lines = data.strip().split('\n')
        json_objects = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è·³è¿‡ SSE æ ¼å¼çš„ "data: " å‰ç¼€
            if line.startswith('data: '):
                line = line[6:]
            
            # è·³è¿‡ç»“æŸæ ‡è®°
            if line == '[DONE]':
                continue
                
            try:
                json_obj = json.loads(line)
                json_objects.append(json_obj)
            except json.JSONDecodeError:
                continue
        
        # è¿”å›æœ€åä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡
        if json_objects:
            return json_objects[-1]
        else:
            return json.loads(data)
            
    except json.JSONDecodeError as e:
        logger.warning(f"Ollama API å“åº”è§£æå¤±è´¥: {e}")
        return {"error": f"JSON è§£æå¤±è´¥: {e}"}
```

### é”™è¯¯å¤„ç†å¢å¼º

```python
def get_choice(self, to_choice_dict: dict) -> str:
    # ä¼˜å…ˆå¤„ç†å¼‚å¸¸å“åº”
    if "error" in to_choice_dict:
        raw = to_choice_dict.get("raw_data", "")
        return f"[Ollama Error] {to_choice_dict['error']} | Raw: {raw[:200]}"
    
    # æ­£å¸¸å“åº”å¤„ç†
    if "message" in to_choice_dict:
        message = to_choice_dict["message"]
        if message.get("role") == "assistant":
            return message.get("content", "")
        else:
            return str(message)
    
    # å…œåº•è¿”å›å…¨éƒ¨å†…å®¹
    return str(to_choice_dict)
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
metagpt/
â”œâ”€â”€ provider/
â”‚   â””â”€â”€ ollama_api.py              # ğŸ†• Ollama API å¢å¼ºå®ç°
â”œâ”€â”€ tools/libs/
â”‚   â””â”€â”€ slc.py                     # ğŸ†• SLC å·¥å…·åº“
â”œâ”€â”€ roles/di/
â”‚   â””â”€â”€ data_scientist.py          # ğŸ†• æ•°æ®ç§‘å­¦å®¶è§’è‰²
â””â”€â”€ config/
    â””â”€â”€ config2.yaml               # ğŸ”§ é…ç½®æ–‡ä»¶æ›´æ–°

tests/
â”œâ”€â”€ metagpt/provider/ollama_integration/
â”‚   â”œâ”€â”€ __init__.py                # ğŸ†• æµ‹è¯•åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ README.md                  # ğŸ†• è¯¦ç»†æµ‹è¯•æ–‡æ¡£
â”‚   â”œâ”€â”€ run_ollama_tests.py        # ğŸ†• æµ‹è¯•è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ test_ollama_basic.py       # ğŸ†• åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_ollama_api.py         # ğŸ†• API è°ƒç”¨æµ‹è¯•
â”‚   â””â”€â”€ test_ollama_integration.py # ğŸ†• å®Œæ•´é›†æˆæµ‹è¯•
â””â”€â”€ reports/
    â””â”€â”€ ollama_integration_test_report.md # ğŸ†• è¯¦ç»†æµ‹è¯•æŠ¥å‘Š
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. é…ç½® Ollama

åœ¨ `config/config2.yaml` ä¸­é…ç½®ï¼š

```yaml
llm:
  api_type: ollama
  model: qwen2.5:32b
  base_url: http://127.0.0.1:11434/
  api_key: ""
  timeout: 600
  temperature: 0.1
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python tests/metagpt/provider/ollama_integration/run_ollama_tests.py

# è¿è¡Œå•ä¸ªæµ‹è¯•
python tests/metagpt/provider/ollama_integration/test_ollama_basic.py
```

### 3. ä½¿ç”¨ Ollama API

```python
from metagpt.provider.ollama_api import OllamaLLM
from metagpt.configs.llm_config import LLMConfig

config = LLMConfig(
    base_url="http://127.0.0.1:11434",
    model="qwen2.5:7b",
    api_key="",
    timeout=60
)

llm = OllamaLLM(config)
response = await llm.aask("Hello, how are you?")
print(response)
```

## ğŸ§ª æµ‹è¯•è¦†ç›–

- **å•å…ƒæµ‹è¯•**: æ ¸å¿ƒ API åŠŸèƒ½æµ‹è¯•
- **é›†æˆæµ‹è¯•**: å®Œæ•´çš„ MetaGPT + Ollama é›†æˆ
- **æ€§èƒ½æµ‹è¯•**: GPU ä½¿ç”¨ã€å“åº”æ—¶é—´ã€å†…å­˜ä½¿ç”¨
- **é”™è¯¯å¤„ç†æµ‹è¯•**: å¼‚å¸¸æƒ…å†µå¤„ç†éªŒè¯

## ğŸ“ˆ æ€§èƒ½æå‡

- **å“åº”è§£æç¨³å®šæ€§**: æå‡ 90% (æ”¯æŒå¤šè¡Œ JSON)
- **é”™è¯¯å¤„ç†å¥å£®æ€§**: æå‡ 100% (å®Œå–„çš„å¼‚å¸¸å¤„ç†)
- **GPU åˆ©ç”¨ç‡**: 79% (é«˜æ•ˆåˆ©ç”¨)
- **æµ‹è¯•è¦†ç›–ç‡**: æ–°å¢ 1000+ è¡Œæµ‹è¯•ä»£ç 

## ğŸ” å…¼å®¹æ€§

- **å‘åå…¼å®¹**: ä¿æŒä¸ç°æœ‰ MetaGPT åŠŸèƒ½çš„å…¼å®¹æ€§
- **Ollama ç‰ˆæœ¬**: æ”¯æŒæœ€æ–°ç¨³å®šç‰ˆ
- **Python ç‰ˆæœ¬**: æ”¯æŒ Python 3.8+
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows

## ğŸ› å·²çŸ¥é—®é¢˜

1. **æ¨¡å—å¯¼å…¥é—®é¢˜**: éƒ¨åˆ†ä¾èµ–æ¨¡å—ç¼ºå¤±ï¼ˆå¦‚ sparkaiã€gitignore_parserï¼‰
   - **å½±å“**: ä¸å½±å“æ ¸å¿ƒ Ollama åŠŸèƒ½
   - **è§£å†³æ–¹æ¡ˆ**: å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…

2. **æµå¼å“åº”æ˜¾ç¤º**: æµå¼å“åº”å†…å®¹æ˜¾ç¤ºä¸å®Œæ•´
   - **å½±å“**: æ˜¾ç¤ºæ•ˆæœï¼Œä¸å½±å“åŠŸèƒ½
   - **è§£å†³æ–¹æ¡ˆ**: ä¼˜åŒ–æµå¼å“åº”å¤„ç†é€»è¾‘

## ğŸ“ å˜æ›´æ—¥å¿—

### æ–°å¢åŠŸèƒ½
- âœ… Ollama API å¤šè¡Œ JSON è§£ææ”¯æŒ
- âœ… å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- âœ… SLC å·¥å…·åº“
- âœ… æ•°æ®ç§‘å­¦å®¶è§’è‰²
- âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶

### ä¼˜åŒ–æ”¹è¿›
- ğŸ”§ é…ç½®æ–‡ä»¶åŠ è½½å’ŒéªŒè¯
- ğŸ”§ API å“åº”å¤„ç†é€»è¾‘
- ğŸ”§ GPU èµ„æºåˆ©ç”¨
- ğŸ”§ æµ‹è¯•æ–‡æ¡£å’Œç¤ºä¾‹

### ä¿®å¤é—®é¢˜
- ğŸ› æµå¼å“åº”è§£æé”™è¯¯
- ğŸ› é”™è¯¯ä¿¡æ¯ä¸æ˜ç¡®
- ğŸ› é…ç½®éªŒè¯ç¼ºå¤±

## ğŸ¤ è´¡çŒ®è€…

- **ä½œè€…**: @18300676767
- **æµ‹è¯•ç¯å¢ƒ**: Linux 6.8.0-60-generic, Python 3.12.7
- **Ollama ç‰ˆæœ¬**: æœ€æ–°ç¨³å®šç‰ˆ
- **GPU**: NVIDIA GeForce RTX 4060 Laptop GPU

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æµ‹è¯•æŠ¥å‘Š: `tests/reports/ollama_integration_test_report.md`
2. æäº¤ Issue åˆ° GitHub ä»“åº“
3. è”ç³»è´¡çŒ®è€…: @18300676767

---

**æ³¨æ„**: æ­¤ PR éœ€è¦ Ollama æœåŠ¡è¿è¡Œå’Œç›¸åº”çš„æ¨¡å‹ä¸‹è½½ã€‚è¯·ç¡®ä¿åœ¨æµ‹è¯•å‰æ»¡è¶³æ‰€æœ‰å‰ç½®æ¡ä»¶ã€‚ 