#!/usr/bin/env python3
"""
Ollama é›†æˆåŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯• MetaGPT ä¸ Ollama çš„é›†æˆåŠŸèƒ½
"""

import asyncio
import json
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("=" * 50)
    print("ğŸ§ª æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("=" * 50)
    
    try:
        from metagpt.provider.ollama_api import OllamaLLM, OllamaEmbeddings
        print("âœ… OllamaLLM å’Œ OllamaEmbeddings å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥ SLC å·¥å…·æ˜¯å¦å­˜åœ¨
        try:
            from metagpt.tools.libs.slc import SLCTool
            print("âœ… SLCTool å¯¼å…¥æˆåŠŸ")
        except ImportError:
            print("âš ï¸  SLCTool æ¨¡å—ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        from metagpt.roles.di.data_scientist import DataScientist
        print("âœ… DataScientist è§’è‰²å¯¼å…¥æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\n" + "=" * 50)
    print("ğŸ“‹ æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½")
    print("=" * 50)
    
    try:
        import yaml
        from metagpt.configs.llm_config import LLMConfig
        
        # è¯»å–é…ç½®æ–‡ä»¶
        with open("config/config2.yaml", "r", encoding="utf-8") as f:
            config_data = yaml.safe_load(f)
        
        print("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ")
        print(f"ğŸ“ é…ç½®æ–‡ä»¶è·¯å¾„: config/config2.yaml")
        
        # æ£€æŸ¥ Ollama é…ç½®
        if "ollama" in config_data:
            ollama_config = config_data["ollama"]
            print(f"ğŸ”§ Ollama é…ç½®: {json.dumps(ollama_config, indent=2, ensure_ascii=False)}")
        else:
            print("âš ï¸  æœªæ‰¾åˆ° Ollama é…ç½®")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return False

async def test_ollama_api():
    """æµ‹è¯• Ollama API åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸš€ æµ‹è¯• Ollama API åŠŸèƒ½")
    print("=" * 50)
    
    try:
        from metagpt.provider.ollama_api import OllamaLLM
        from metagpt.configs.llm_config import LLMConfig
        
        # åˆ›å»ºé…ç½®
        config = LLMConfig(
            base_url="http://127.0.0.1:11434",
            model="qwen2.5:7b",
            api_key="",
            timeout=60
        )
        
        print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
        print(f"   - Base URL: {config.base_url}")
        print(f"   - Model: {config.model}")
        print(f"   - Timeout: {config.timeout}s")
        
        # åˆ›å»º OllamaLLM å®ä¾‹
        llm = OllamaLLM(config)
        print("âœ… OllamaLLM å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ¶ˆæ¯
        messages = [
            {"role": "user", "content": "Hello, how are you?"}
        ]
        
        print(f"ğŸ“ æµ‹è¯•æ¶ˆæ¯: {messages[0]['content']}")
        
        # å°è¯•è°ƒç”¨ APIï¼ˆéœ€è¦ Ollama æœåŠ¡è¿è¡Œï¼‰
        try:
            response = await llm.aask("Hello, how are you?")
            print(f"âœ… API è°ƒç”¨æˆåŠŸ")
            print(f"ğŸ“„ å“åº”å†…å®¹: {response[:100]}...")
        except Exception as api_error:
            print(f"âš ï¸  API è°ƒç”¨å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ Ollama æœåŠ¡æœªè¿è¡Œï¼‰: {api_error}")
            print("ğŸ’¡ è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        
        return True
    except Exception as e:
        print(f"âŒ Ollama API æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_slc_tool():
    """æµ‹è¯• SLC å·¥å…·åº“"""
    print("\n" + "=" * 50)
    print("ğŸ› ï¸  æµ‹è¯• SLC å·¥å…·åº“")
    print("=" * 50)
    
    try:
        from metagpt.tools.libs.slc import SLCTool
        
        # æ£€æŸ¥ SLC å·¥å…·æ˜¯å¦å­˜åœ¨
        try:
            from metagpt.tools.libs.slc import SLCTool
            # åˆ›å»º SLC å·¥å…·å®ä¾‹
            slc_tool = SLCTool()
            print("âœ… SLCTool å®ä¾‹åˆ›å»ºæˆåŠŸ")
            
            # æ£€æŸ¥å·¥å…·æ–¹æ³•
            methods = [method for method in dir(slc_tool) if not method.startswith('_')]
            print(f"ğŸ”§ å¯ç”¨æ–¹æ³•: {methods}")
        except ImportError:
            print("âš ï¸  SLCTool æ¨¡å—ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        return True
    except Exception as e:
        print(f"âŒ SLC å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_scientist_role():
    """æµ‹è¯•æ•°æ®ç§‘å­¦å®¶è§’è‰²"""
    print("\n" + "=" * 50)
    print("ğŸ‘¨â€ğŸ”¬ æµ‹è¯•æ•°æ®ç§‘å­¦å®¶è§’è‰²")
    print("=" * 50)
    
    try:
        from metagpt.roles.di.data_scientist import DataScientist
        
        # åˆ›å»ºæ•°æ®ç§‘å­¦å®¶è§’è‰²å®ä¾‹
        data_scientist = DataScientist()
        print("âœ… DataScientist è§’è‰²åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥è§’è‰²å±æ€§
        print(f"ğŸ­ è§’è‰²åç§°: {data_scientist.name}")
        print(f"ğŸ“ è§’è‰²ç±»å‹: {type(data_scientist).__name__}")
        
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®ç§‘å­¦å®¶è§’è‰²æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ollama_service():
    """æµ‹è¯• Ollama æœåŠ¡çŠ¶æ€"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯• Ollama æœåŠ¡çŠ¶æ€")
    print("=" * 50)
    
    try:
        import requests
        
        # æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ
        try:
            response = requests.get("http://127.0.0.1:11434/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print("âœ… Ollama æœåŠ¡è¿è¡Œæ­£å¸¸")
                print(f"ğŸ“¦ å¯ç”¨æ¨¡å‹æ•°é‡: {len(models.get('models', []))}")
                for model in models.get('models', [])[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæ¨¡å‹
                    print(f"   - {model.get('name', 'Unknown')}")
            else:
                print(f"âš ï¸  Ollama æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
        except requests.exceptions.RequestException:
            print("âŒ Ollama æœåŠ¡æœªè¿è¡Œæˆ–æ— æ³•è¿æ¥")
            print("ğŸ’¡ è¯·å¯åŠ¨ Ollama æœåŠ¡: ollama serve")
        
        return True
    except Exception as e:
        print(f"âŒ Ollama æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ MetaGPT Ollama é›†æˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print(f"â° æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ Python ç‰ˆæœ¬: {sys.version}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {Path.cwd()}")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("é…ç½®æ–‡ä»¶åŠ è½½", test_config_loading),
        ("SLC å·¥å…·åº“", test_slc_tool),
        ("æ•°æ®ç§‘å­¦å®¶è§’è‰²", test_data_scientist_role),
        ("Ollama æœåŠ¡çŠ¶æ€", test_ollama_service),
        ("Ollama API åŠŸèƒ½", test_ollama_api),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:<20} {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ“ˆ æµ‹è¯•é€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Ollama é›†æˆåŠŸèƒ½æ­£å¸¸")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®å’ŒæœåŠ¡çŠ¶æ€")
    
    return passed == total

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 